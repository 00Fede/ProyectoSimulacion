usar smote

decidir cuantas

definir porcentajes

ir aumentando el porcentaje (hasta 15%)

sobre el conjunto de entrenamiento. 

mirar sensibilidad y especifidad

one hot encoding cuando no son niveles

------

Uso de Smote

porcentaje de muestras de clase 1 original = 6.5789473684211%
porcentaje de muestras de clase 0 original = 93.4210526315790%

Sin duda se requiere SMOTE

con th = 0.3 y 5 vecinos positivos
2912 muestras resultantes, 328 muestras artificiales
clase 0 = 70%
Clase 1 = 30%

Ya ahi menos desbalance, pruebo si configurando parametros puede conseguirse algo mejor

th=0.15 num_vecinos = 5

2920 muestras --- no hay muchos cambios con el anterior

th=0.30 num_vecinos = 8

N=3920

clase 0 = 58%
clase 1 = 42%

Muestras muy balanceadas, es dificil verificar si el smote fue realizado correctamente, se
deja en consideración de la funcion y sus parametros. Aunque si hay formas:
** La varianza de las muestras reales, respecto a col 5 es 5.23e+10. Después de aplicar
smote la varianza de esa columna es 6.09e+10.. La diferencia no es tan abismal lo que indica
que los valores generados son acordes a la variable.

Algunas variables categoricas codificadas como 3 o 4 tenian valores generados por smote
decimales. i.e 0.333 , 0.555... para solucionar este problema y las muestras generadas se ajusten
a las caracteristicas reales, se aplica round al conjunto de los datos con SMOTE.


-------
Seleccion de Variables

Se descartan inicialmente columnas 15,16,17 ya que su indice de correlacion es tan bajo que produce
NaNs en los metodos de seleccion

////////////Segun matriz Correlacion pearson

variables con mas correlacion: 1,3,4,6,7,10,11,12

//////////////Indice de fisher, se busca que sea grande

Indice de Fisher: 
0.15628   0.0024284      0.6221      0.6221   0.0064198     0.31171     0.70084   0.0047484    0.023114      1.2093     0.88351      0.7346     0.10416  7.2034e-06    0.067269    0.030474
Indice de Fisher Normalizado: 
0.12923    0.002008     0.51441     0.51441   0.0053086     0.25775     0.57953   0.0039264    0.019113           1     0.73058     0.60744    0.086132  5.9565e-06    0.055625    0.025199

Segun fisher, variables con mas correlacion son cols 3,4,7,10,11,12.

// Corriendo SFS

Final columns included:  1 2 4 6 9 11 16 
La eficiencia obtenida fue = 0.93631 +- 0.011498

// Algoritmo Genetico
Utilizando funcion forest para la evaluacion. metodo de seleccion parece ser seleccion proporcional o ranking

1 2 4 5 6 9 11 16

La eficiencia obtenida fue = 0.93207 +- 0.010076


//Usando extraccion de caracteristicas PCA
Se seleccionaron 7 componentes principales

//LASSO no es usado
La eficiencia obtenida fue = 0.87534 +- 0.018337

------ Tirar modelos

Inicialmente tiramos estos modelos con el dataset sobremuestreado con smotes,
ya que sabemos que si lo tiramos no van a dar buenos resultados debido al desbalance.
Lo tiramos también con la codificación, peroooo sin selecciónn/extracción de caracterisiticas
para poder comparar luegos los resultados. capichi.

las columnas 15,16,17 del dataset tienen varianza cero, esto afecta la ejecución de algunos
modelos, por tanto se remueven.


--->> Tirar funciones discriminantes gaussianas
Intente tirar fitcdiscr con CrossVal On pero no supe hacer la implementacion
Se tira implementación segun el profe, de 10 kfolds.

La eficiencia obtenida de funciones discr. gauss. es 0.92412 +-0.026465









